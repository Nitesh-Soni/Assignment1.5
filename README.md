1. Explain the main sources of Data flood.

There is a huge amount of information available online. And its volume is growing at lightning speed. Each minute on average, more than 200 million emails move across the Internet (though most are spam). Twitter users post more than 300,000 new tweets. 
People across the globe share more than 38,000 Instagrams. YouTube users upload another 100 hours of video.Google processes more than 3.6 millionwebsearches. And 2.2 million things on Facebook get a “like” or a comment.
But the Internet isn’t the only numbers-driven environment packed with information. Scientists, too, have more information than ever before. It comes from the study of volumes of raw facts, called data.
For example, biologists collect enormous numbers of measurements on millions of cells and everything inside them. Astronomers fill banks of hard drives with observations of stars, galaxies and energy in deep space. Earth scientists assemble detailed snapshots of weather, including patterns of winds and waves throughout the world.

2. What is the difference between Data and Big data.

Big Data:
            Big Data is a concept in Software Engineering which we use when we have a large sets of machine generated data, which in most of the cases is unstructured and not easy to use with traditional RDBMS concepts. 
    
Data:
                    Data Analytics on the other hand is more of analyzing data which could be structured or unstructured. Even though they both sound similar, there have different objectives. Out of huge data sets, when you want to narrow down a piece of customized data, we do number of steps in analyzing like investigating data, cleaning, transforming and getting the result.
 
3 )Main reason behind the Hadoop become the solution for Data explosion.

Apache Hadoop is 100% open source, and pioneered a fundamentally new way of storing and processing data. Instead of relying on expensive, proprietary hardware and different systems to store and process data, Hadoop enables distributed parallel processing of huge amounts of data across inexpensive, industry-standard servers that both store and process the data, and can scale without limits. With Hadoop, no data is too big. And in today’s hyperconnected world where more and more data is being created every day, Hadoop's breakthrough advantages mean that businesses and organizations can now find value in data that was recently considered useless.
But what exactly is Hadoop, and what makes it so special? In it’s basic form, it is a way of storing enormous data sets across distributed clusters of servers and then running "distributed" analysis applications in each cluster. It's designed to be robust, in that the Big Data applications will continue to run even when failures occur in individual servers or clusters.
It's also designed to be efficient, because it doesn't require the applications to shuttle huge volumes of data across the network. It has two main parts; a data processing framework (MapReduce) and a distributed file system (HDFS) for data storage. 
These are the components that are at the heart of Hadoop and really make things happen.
